{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing And Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mJupyter server crashed. Unable to connect. \n",
      "\u001b[1;31mError code from Jupyter: 1\n",
      "\u001b[1;31musage: jupyter.py [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "\u001b[1;31m                  [--paths] [--json] [--debug]\n",
      "\u001b[1;31m                  [subcommand]\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mJupyter: Interactive Computing\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mpositional arguments:\n",
      "\u001b[1;31m  subcommand     the subcommand to launch\n",
      "\u001b[1;31m\n",
      "\u001b[1;31moptions:\n",
      "\u001b[1;31m  -h, --help     show this help message and exit\n",
      "\u001b[1;31m  --version      show the versions of core jupyter packages and exit\n",
      "\u001b[1;31m  --config-dir   show Jupyter config dir\n",
      "\u001b[1;31m  --data-dir     show Jupyter data dir\n",
      "\u001b[1;31m  --runtime-dir  show Jupyter runtime dir\n",
      "\u001b[1;31m  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "\u001b[1;31m                 format.\n",
      "\u001b[1;31m  --json         output paths as machine-readable json\n",
      "\u001b[1;31m  --debug        output debug information about paths\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mAvailable subcommands:\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mJupyter command `jupyter-notebook` not found. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# loda training datasets\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"./data/datasets/train_qWM28Yl.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# identify important features for training model with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify important columns.\n",
    "# engine_type, model, make, population_density, age_of_policyholder, age_of_car, area_cluster, fuel_type, max_torque, max_power, airbags, is_parking_sensors, is_parking_camera, cylinder, transmission_type, gear_box, length, width, height, gross_weight, is_speed_alert, is_claim\n",
    "\n",
    "# features = [ 'engine_type', 'model', 'make', 'population_density', 'age_of_policyholder', 'age_of_car', 'area_cluster', 'fuel_type', 'max_torque', 'max_power', 'airbags', 'is_parking_sensors', 'is_parking_camera', 'cylinder', 'transmission_type', 'gear_box', 'length', 'width', 'height', 'gross_weight', 'is_speed_alert', \"is_claim\" ]\n",
    "\n",
    "print( \"features in dataset:\\n\".upper(), df.columns )\n",
    "\n",
    "features = [ 'engine_type', 'fuel_type', 'population_density', 'cylinder', 'transmission_type', 'gear_box', 'length', 'width', 'height', 'gross_weight', 'is_speed_alert', \"is_claim\" ]\n",
    "print( \"\\nSelected Features:\\n\".upper(), features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[features]\n",
    "# assume there is no duplicates or NA values or rows.\n",
    "# df.dropna(inplace=True, axis=0 )\n",
    "# df.drop_duplicates(inplace=True,)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bhp = torque * rpm / 5252\n",
    "print(\"data shape:\", df.shape )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### remove max torque and power from features, until an optimal idea is found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # preprocess max_torque and max_power features. | remove them\n",
    "# import re\n",
    "# text = \"91Nm@4250rpm\"\n",
    "# text = str(text).lower()\n",
    "# text = text.split(\"@\")\n",
    "# text[0] = re.sub(\"nm\", '', text[0])\n",
    "# text[1] = re.sub(\"rpm\", '', text[1])\n",
    "# text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import numpy as np\n",
    "\n",
    "# ss = StandardScaler()\n",
    "# a = [[4], [5], [7], [3]]\n",
    "# scaler = ss.fit( a )\n",
    "# r = scaler.transform(a)\n",
    "# # rr = [ i[0] for i in r]\n",
    "# i = scaler.inverse_transform(r)\n",
    "# print(\"Norm\\n\", r)\n",
    "# print(\"Inverse\\n\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try inverse transform, policu holder age\n",
    "# dd = df['age_of_policyholder'][ : 5]\n",
    "# dd = [ [d,] for d in dd ]\n",
    "# dd\n",
    "# scaler.inverse_transform(dd)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class to transform data, normalise, standardize and scale features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, LabelEncoder, StandardScaler\n",
    "\n",
    "_standardScalerObj = StandardScaler()\n",
    "\n",
    "class Preprocss():\n",
    "    '''preprocess features and scale them.'''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def __str__(self) -> str:\n",
    "        return '''preprocess features and scale them.'''\n",
    "        \n",
    "    def transmission_type_norm(self, value ):\n",
    "        '''0 -> automatic | 1 -> manuel'''\n",
    "        value = str(value).lower()\n",
    "        if 'automatic' == value: return 0\n",
    "        elif 'manual' == value: return 1\n",
    "        else: return 3\n",
    "        \n",
    "    def fuel_type_norm(self, value ):\n",
    "        '''0 -> petrol | 1 ->diesel | 2 -> cng | 3 -> unknown '''\n",
    "        value = str(value).lower()\n",
    "        if value == 'petrol': return 0\n",
    "        elif value == 'diesel': return 1\n",
    "        elif value == 'cng': return 2\n",
    "        else: return 3\n",
    "    \n",
    "    def speed_alert(self, value):\n",
    "        '''0 -> No | 1 -> Yes'''\n",
    "        value = str(value).lower()\n",
    "        if value == 'no': return 0\n",
    "        elif value == 'yes': return 1\n",
    "        else: return 0\n",
    "    \n",
    "    def engine( self, value ):\n",
    "        '''I can't use labelencoder from scikit-learn. its not optimal'''\n",
    "        '''['F8D Petrol Engine', '1.2 L K12N Dualjet', '1.0 SCe',\n",
    "       '1.5 L U2 CRDi', '1.5 Turbocharged Revotorq', 'K Series Dual jet',\n",
    "       '1.2 L K Series Engine', 'K10C', 'i-DTEC', 'G12B',\n",
    "       '1.5 Turbocharged Revotron']'''\n",
    "        if value != None:\n",
    "            value = str(value).lower()\n",
    "            if value == 'f8d petrol engine'.lower(): return 0\n",
    "            elif value == '1.2 L K12N Dualjet'.lower(): return 1\n",
    "            elif value == '1.0 SCe'.lower(): return 2\n",
    "            elif value == '1.5 L U2 CRDi'.lower(): return 3\n",
    "            elif value == '1.5 Turbocharged Revotorq'.lower(): return 4\n",
    "            elif value == 'K Series Dual jet'.lower(): return 5\n",
    "            elif value == '1.2 L K Series Engine'.lower(): return 6\n",
    "            elif value == 'K10C'.lower(): return 7\n",
    "            elif value == 'i-DTEC'.lower(): return 8\n",
    "            elif value == 'G12B'.lower(): return 9\n",
    "            elif value == '1.5 Turbocharged Revotron'.lower(): return 10\n",
    "        else: return value\n",
    "        \n",
    "    def standard_scaler(self, value ):\n",
    "        '''use standard scaler to scal the age of the car'''\n",
    "        array = [[value],]\n",
    "        _standardScalerObj.fit(array)\n",
    "        res = _standardScalerObj.transform(array)\n",
    "        return res[0][0]\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproObj = Preprocss()\n",
    "df['engine_type'] = df['engine_type'].apply( preproObj.engine )\n",
    "df['is_speed_alert'] = df['is_speed_alert'].apply( preproObj.speed_alert )\n",
    "df['fuel_type'] = df['fuel_type'].apply( preproObj.fuel_type_norm )\n",
    "df['transmission_type'] = df['transmission_type'].apply( preproObj.transmission_type_norm )\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Imblearn to balance classes in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise class distributions before over sampling.\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title(\"Class Distribution Before Undersampling\")\n",
    "sns.countplot(data=df, x=\"is_claim\")\n",
    "plt.xlabel(\"Classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tomeklink and create object with strategy of reducing from majority class. \n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "# tomekObj = TomekLinks(sampling_strategy='auto')\n",
    "tomekObj = TomekLinks()\n",
    "\n",
    "# get target and feature data in variables.\n",
    "target = df['is_claim']\n",
    "features = df[['engine_type','fuel_type','population_density','cylinder','transmission_type','gear_box','length','width','height','gross_weight','is_speed_alert']]\n",
    "# \n",
    "print( f\"Data shape: {features.shape}\" )\n",
    "print(f\"target distribution before undersampling \\n{target.value_counts()}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "for i in range(10):\n",
    "    x_sample, y_sample = tomekObj.fit_resample(features, target)\n",
    "# \n",
    "print(f\"Data shape: {x_sample.shape}\" )\n",
    "print(f\"target distribution after undersampling \\n{y_sample.value_counts()}\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save new data to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/processed_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "claim-envs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37f902d1d7c01adca42c0773e4b3782f93bca033ca310e8dedcc92a71a885b45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
